{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "060c3cee",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e0a70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from mysql import connector # allows us to connect Python to MySQL\n",
    "from dotenv import load_dotenv # load sensitive environmental variables from .env file\n",
    "load_dotenv() # this must be run in order to grant getenv function permission to access objects in .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d1d55",
   "metadata": {},
   "source": [
    "## Define Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2d5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# retrieve sensitive information stored in local .env file\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "API_HOST = os.getenv(\"API_HOST\") \n",
    "\n",
    "# load MySQL credentials  \n",
    "db_host = os.getenv(\"MYSQL_HOST\")\n",
    "db_port = os.getenv(\"MYSQL_PORT\")\n",
    "db_user = os.getenv(\"MYSQL_USER\")\n",
    "db_pssword = os.getenv(\"MYSQL_PASSWORD\")\n",
    "db_db = os.getenv(\"MYSQL_DATABASE\")\n",
    "db_table = os.getenv(\"SQL_TABLE\")\n",
    "\n",
    "# API Request\n",
    "url = f\"https://api.eia.gov/v2/electricity/retail-sales/data/?api_key={API_KEY}&frequency=annual&data[0]=customers&data[1]=price&data[2]=revenue&data[3]=sales&start=2019&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000\"\n",
    "url = f\"https://api.eia.gov/v2/electricity/retail-sales/data/?api_key={API_KEY}&frequency=annual&data[0]=customers&data[1]=price&data[2]=revenue&data[3]=sales&start=2019&sort[0][column]=period&sort[0][direction]=desc&offset=0&length=5000\"\n",
    "\n",
    "# don't forget to add \"api_key =\" and \"&\" after you insert API KEY variable\n",
    "# full documentation here: https://www.eia.gov/opendata/documentation/APIv2.1.0.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14616ebf",
   "metadata": {},
   "source": [
    "## Workflow Overview\n",
    "\n",
    "We will define individual functions that represent different stages of the ETL process, then string it all together as one comprehensive function to execute. Skip to \"Full ETL Pipeline\" section to see the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf7712",
   "metadata": {},
   "source": [
    "## Extract Using GET Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56d926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract using GET request\n",
    "def get_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        json_data = response.json()\n",
    "        rows_returned = int(json_data[\"response\"][\"total\"])\n",
    "        if rows_returned > 5000:\n",
    "            print(f\"Success! {rows_returned} records exists, but only 5,000 can be returned due to API limit.\")\n",
    "        else:\n",
    "            print(f\"Success! {rows_returned} records were returned.\")\n",
    "        return json_data[\"response\"][\"data\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during the extraction stage: {e}\")\n",
    "        return None"
    "        print(f\"Error occurred during the extraction stage: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e9ac0",
   "metadata": {},
   "source": [
    "## Transform Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fe2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer JSON data into a structured format\n",
    "def store_data(raw_data):\n",
    "    # creating a list that will store each record\n",
    "    rows = [] \n",
    "    # store each field within a record into a variable\n",
    "    for record in raw_data:\n",
    "        period = record[\"period\"] # \"period\" key to access value\n",
    "        stateid = record[\"stateid\"]\n",
    "        sectorid = record[\"sectorid\"]\n",
    "        customers = record[\"customers\"]\n",
    "        price = record[\"price\"]\n",
    "        revenue = record[\"revenue\"]\n",
    "        sales = record[\"sales\"]\n",
    "        \n",
    "        # append each field into the empty list as dictionaries\n",
    "        rows.append({\"period\":period, \"stateid\":stateid, \"sectorid\":sectorid,\"customers\":customers, \"price\":price, \"revenue\":revenue, \"sales\":sales})\n",
    "    return rows"
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba652b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the data into a Python DataFrame object\n",
    "# removing any rows with null values\n",
    "def to_df(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    dfn = len(df)\n",
    "    df = df.dropna()\n",
    "    print(f\"{dfn - len(df)} rows containing nulls were dropped, {len(df)} records remain.\")\n",
    "    return df"
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116bec6",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff69bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to MySQL database\n",
    "def db_connect(db_host, db_port, db_user, db_pssword, db_db):\n",
    "    db_connection = None\n",
    "    try:\n",
    "        db_connection = connector.connect(\n",
    "            host = db_host,\n",
    "            user = db_user,\n",
    "            passwd = db_pssword,\n",
    "            database = db_db,\n",
    "            port = db_port,\n",
    "            connection_timeout = 10 \n",
    "        )\n",
    "        print(f\"Connection to schema: {db_db} successful ✅\")\n",
    "        return db_connection\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during the loading stage: {e}\")"
    "        print(f\"Error occurred during the loading stage: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa7c904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table in our database\n",
    "def create_table(db_connection):\n",
    "    SQL_CREATE_TABLE = f\"\"\"\n",
    "    CREATE TABLE {db_table} (\n",
    "\t\tperiod VARCHAR(25) NOT NULL,\n",
    "        stateid VARCHAR(5) NOT NULL,\n",
    "        sectorid VARCHAR(10) NOT NULL,\n",
    "        customers INT NOT NULL,\n",
    "        price INT NOT NULL,\n",
    "        revenue INT NOT NULL,\n",
    "        sales INT NOT NULL,\n",
    "        PRIMARY KEY (period, stateid, sectorid)\n",
    "    );\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cursor = db_connection.cursor()\n",
    "        cursor.execute(SQL_CREATE_TABLE)\n",
    "        db_connection.commit()\n",
    "        print(f\"{db_table} created successfully ✅\")\n",
    "\n",
    "    except connector.Error as e:\n",
    "        if e.errno == 1050:\n",
    "            print(f\"\"\"The table: \"{db_table}\" has already been created.\"\"\")\n",
    "        else:\n",
    "            print(f\"❌ [CREATING TABLE ERROR]: '{e}'\")\n",
    "            return"
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe96a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert or update data in the database from the dataframe\n",
    "# insert or update data in the database from the dataframe\n",
    "def insert_into_table(db_connection, df, db_table):\n",
    "\n",
    "    cursor = db_connection.cursor()\n",
    "\n",
    "    INSERT_DATA_SQL_QUERY = f\"\"\"\n",
    "        INSERT INTO {db_table}\n",
    "        VALUES(%s, %s, %s, %s, %s, %s, %s) AS src\n",
    "        ON DUPLICATE KEY UPDATE\n",
    "        period = src.period,\n",
    "        stateid = src.stateid,\n",
    "        sectorid = src.sectorid,\n",
    "        customers = src.customers,\n",
    "        price = src.price,\n",
    "        revenue = src.revenue,\n",
    "        sales = src.sales;\n",
    "        \"\"\"\n",
    "    # create a list of tuples from the dataframe values in array form \n",
    "    # create a list of tuples from the dataframe values in array form \n",
    "    data_as_tuples = [tuple(x) for x in df.to_numpy()]\n",
    "    # can also use df.itertuples() to iterate over DF rows as tuples\n",
    "\n",
    "    # execute the query\n",
    "    # execute the query\n",
    "    cursor.executemany(INSERT_DATA_SQL_QUERY, data_as_tuples)\n",
    "    db_connection.commit()\n",
    "    print(f\"{cursor.rowcount} records inserted or updated successfully ✅\")"
    "    print(f\"{cursor.rowcount} records inserted or updated successfully ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b50ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return how many rows exists in the database table\n",
    "def return_db_rows(db_connection):\n",
    "    RETURN_ROW_SQL_QUERY = f\"\"\"\n",
    "        SELECT COUNT(*) FROM {db_table};\n",
    "        \"\"\"\n",
    "    cursor = db_connection.cursor()\n",
    "    cursor.execute(RETURN_ROW_SQL_QUERY)\n",
    "    results = cursor.fetchone()[0]\n",
    "    print(f\"There are {results} rows in the table.\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a335f",
   "metadata": {},
   "source": [
    "## Full ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f7371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# piecing all the functions together to form the complete ETL pipeline function\n",
    "def run_pipeline():\n",
    "    raw_data = get_data(url)\n",
    "\n",
    "    if raw_data is not None:\n",
    "        data = store_data(raw_data)\n",
    "        df = to_df(data)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    db_connection = db_connect(db_host, db_port, db_user, db_pssword, db_db)\n",
    "\n",
    "    if db_connection is not None:\n",
    "        # create_table(db_connection)  # only run this to initialize table in new database\n",
    "        insert_into_table(db_connection, df, db_table)\n",
    "        return_db_rows(db_connection)\n",
    "        db_connection.close()\n",
    "    else:\n",
    "        print(\"Failed to connect to DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25db9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! 2232 records were returned.\n",
      "372 rows containing nulls were dropped, 1860 records remain.\n",
      "Connection to schema: eia_electricity_sale successful ✅\n",
      "sales created successfully ✅\n",
      "1860 records inserted or updated successfully ✅\n",
      "There are 1860 rows in the table.\n"
     ]
    }
   ],
   "source": [
    "# run this command to run the full pipeline\n",
    "run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
